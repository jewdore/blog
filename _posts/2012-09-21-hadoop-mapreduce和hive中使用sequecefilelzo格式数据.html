---
layout: post
title: hadoop mapreduce和hive中使用SequeceFile+lzo格式数据
---

<p>一. hadoop中常见的压缩和解压数据格式</p><p>　　随着处理的数据量越来越大，在HDFS中存储压缩数据，不仅能节省集群的存储空间，而且可以减少磁盘io。对于跨集群数据传输来说，更能节约网络带宽。常见的用于hadoop的压缩文件格式有：</p>压缩格式工具算法文件扩展名多文件可分割性DEFLATE*无DEFLATE.deflate不不GzipgzipDEFLATE.gz不不ZIPzipDEFLATE.zip是是，在文件范围内bzip2bzip2bzip2.bz2不是LZOlzopLZO.lzo不不<p>   gzip和ZIP是比较通用的压缩方式，在空间和时间的处理上比较平衡。</p><p>   bzip2的压缩比gzip或ZIP更有效，但是速度较慢，会使job的瓶颈转移到CPU上。</p><p>   lzo的压缩和解压速度比gzip或ZIP更快，但是压缩效率偏低。</p><p>   总的来说，压缩比：bzip2 &gt; gzip &gt; lzo，速度：lzo &gt; gzip &gt; bzip2</p><p>　　除了采用这几种压缩格式，SequeceFile也是一种比较好的选择。SequeceFile是Hadoop API提供的一种二进制文件支持。这种二进制文件直接将&lt;key, value&gt;对序列化到文件中。一般对小文件可以使用这种文件合并，即将文件名作为key，文件内容作为value序列化到大文件中。这种文件格式有以下好处：　　  1. 支持压缩，且可定制为基于Record或Block压缩（Block级压缩性能较优）　　  2. 可分割　　  3. 使用方便，因为是Hadoop框架提供的API。　　  4. 缺点是是需要一个合并文件的过程，且合并后的文件将不方便查看。</p><p>　　对于mapreduce任务来说，更关心的一点是数据的&ldquo;可分割性(splitable)&rdquo;。如果数据不能分割，则意味着一个map只能处理一个文件，而这个文件可能会较大，这样就无法利用整个集群的并行处理能力，还会损失job的本地性优势。</p><p>　　使用最快的速度压缩，还是最优的空间压缩，需要根据具体的业务，找到一个平衡点。如果业务更在意压缩和解压时间，对于压缩比不是那么在意，使用lzo是一种比较好的选择。虽然lzo(或gzip)等压缩算法本身是不支持分割的，但是sequence file是可以分块的，所以sequence file格式的文件，再配上lzo(或gzip)的压缩格式，就可实现lzo(或gzip)压缩文件方式的splitable。</p><p>   由于开源协议的不同，在hadoop 0.20以后使用lzo，需要单独安装包。详见Hadoop-LZO项目主页：https://github.com/toddlipcon/hadoop-lzo</p><p>二. hive中使用lzo压缩格式输出</p><p>   下面介绍在hive的job中怎么使用lzo数据的压缩输出。</p><p>   这个例子中是以aid为key，join两个表的数据。数据aid_pid和aid_spuid都是这种以\t分割，\n结束的格式：</p><p>　　　　10056889 -1073122434　　　　10059859 -855371037　　　　10067977 -485421398　　　　10086787 -334639064</p><p>  执行hive命令的shell脚本如下：</p><pre class="brush:java;gutter:false;">#!/bin/shexport HIVE_HOME=/home/admin/hiveexport PATH=$HIVE_HOME/bin:$PATHhive -e " DROP TABLE test_aid_pid; CREATE EXTERNAL TABLE test_aid_pid (     aid BIGINT,     pid STRING )ROW FORMAT DELIMITEDFIELDS TERMINATED BY '\t' stored as textfile location '/test/baoniu/aid_pid';"hive -e " DROP TABLE test_aid_spuid; CREATE EXTERNAL TABLE test_aid_spuid (     aid BIGINT,     spuid STRING )ROW FORMAT DELIMITEDFIELDS TERMINATED BY '\t' stored as textfile location '/test/baoniu/aid_spuid';"## joinhive -e " DROP TABLE test_aid_pid_spuid; CREATE TABLE test_aid_pid_spuid (     aid BIGINT,     pid STRING,     spuid STRING)ROW FORMAT DELIMITEDFIELDS TERMINATED BY '\t' stored as SEQUENCEFILE location '/test/baoniu/aid_pid_spuid';"hive -e "set hive.exec.compress.output=true;set mapred.output.compress=true;set mapred.output.compression.type=BLOCK;set mapred.output.compression.codec=org.apache.hadoop.io.compress.LzoCodec;INSERT OVERWRITE TABLE test_aid_pid_spuid SELECT a.aid, a.pid, b.spuidFROM test_aid_pid a JOIN test_aid_spuid b ON (a.aid = b.aid ) "</pre>

了解破碎机常识：<a href='http://www.crushermillsupplier.com'>crusher mill supplier</a>